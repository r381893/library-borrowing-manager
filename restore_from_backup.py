
import firebase_admin
from firebase_admin import credentials, firestore
import pandas as pd
import os
import glob

# 1. åˆå§‹åŒ– Firebase
key_path = 'key.json' 
if not os.path.exists(key_path):
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° key.json é‘°åŒ™æª”æ¡ˆï¼ç„¡æ³•é€£ç·šã€‚")
    input("æŒ‰ Enter é›¢é–‹...")
    exit()

try:
    cred = credentials.Certificate(key_path)
    firebase_admin.initialize_app(cred)
    db = firestore.client()
    print("âœ… å·²é€£ç·šåˆ°é›²ç«¯è³‡æ–™åº«")
except Exception as e:
    if 'The default Firebase app already exists' in str(e):
        db = firestore.client()
    else:
        print(f"âŒ é€£ç·šå¤±æ•—: {e}")
        input("æŒ‰ Enter é›¢é–‹...")
        exit()

# 2. é¸æ“‡ Excel æª”æ¡ˆ
excel_files = glob.glob('*.xlsx')
if not excel_files:
    print("âŒ æ‰¾ä¸åˆ°ä»»ä½• .xlsx Excel æª”æ¡ˆã€‚")
    input("æŒ‰ Enter é›¢é–‹...")
    exit()

print("\n=== è«‹é¸æ“‡è¦åŒ¯å…¥çš„æª”æ¡ˆ ===")
for i, f in enumerate(excel_files):
    print(f"{i+1}. {f}")

choice = input("\nè«‹è¼¸å…¥ç·¨è™Ÿ (ä¾‹å¦‚ 1): ")
try:
    idx = int(choice) - 1
    target_file = excel_files[idx]
except:
    print("âŒ è¼¸å…¥éŒ¯èª¤ã€‚")
    input("æŒ‰ Enter é›¢é–‹...")
    exit()

print(f"\nğŸ“‚ æ­£åœ¨è®€å–: {target_file} ...")
try:
    df = pd.read_excel(target_file)
except Exception as e:
    print(f"âŒ è®€å– Excel å¤±æ•—: {e}")
    input("æŒ‰ Enter é›¢é–‹...")
    exit()

# 3. ç¢ºèªåŒ¯å…¥æ¨¡å¼
print(f"Excel ä¸­å…±æœ‰ {len(df)} ç­†è³‡æ–™ã€‚")
print("\nâš ï¸  è­¦å‘Šï¼šåŒ¯å…¥åŠŸèƒ½æœƒå°‡ Excel è³‡æ–™ä¸Šå‚³åˆ°é›²ç«¯ã€‚")
print("1. ã€å®‰å…¨æ¨¡å¼ã€‘åªæ–°å¢ ID ä¸å­˜åœ¨çš„æ›¸ (ä¸æœƒè¦†è“‹èˆŠæ›¸)")
print("2. ã€è¦†è“‹æ¨¡å¼ã€‘ä¾ç…§ ID å¼·åˆ¶æ›´æ–°æ‰€æœ‰å…§å®¹ (è‹¥ ID ç›¸åŒæœƒè¢«è¦†è“‹)")

mode = input("è«‹é¸æ“‡æ¨¡å¼ (1 æˆ– 2): ")

batch = db.batch()
batch_count = 0
total_processed = 0

print("\nğŸš€ é–‹å§‹åŒ¯å…¥...")

# ç‚ºäº†åŠ é€Ÿæª¢æŸ¥ï¼Œå…ˆæŠ“å–ç¾æœ‰ ID (å¦‚æœæ•¸é‡å¾ˆå¤§ï¼Œé€™ç¨®æ–¹å¼å¯èƒ½è¦å„ªåŒ–ï¼Œä½† 5000 ç­†é‚„å¥½)
existing_ids = set()
if mode == '1':
    print("ğŸ” æ­£åœ¨æƒæç¾æœ‰é›²ç«¯è³‡æ–™...")
    docs = db.collection('books').stream()
    for doc in docs:
        data = doc.to_dict()
        if 'id' in data:
            existing_ids.add(str(data['id']))

books_ref = db.collection('books')

for index, row in df.iterrows():
    # è™•ç†æ¬„ä½å°æ‡‰
    # Excel æ¬„ä½å¯èƒ½å«åš: 'ç³»çµ±ID', 'åˆ†é¡', 'æ›¸å', 'ä½œè€…', 'å€Ÿé–±äºº_å‚™è¨»', 'æ—¥æœŸ'
    # æˆ–æ˜¯èˆŠç‰ˆçš„: 'id', 'category', 'title', ...
    
    # å˜—è©¦æŠ“å– ID
    sys_id = row.get('ç³»çµ±ID') or row.get('id')
    
    # å¦‚æœæ²’æœ‰ IDï¼Œå°±æ ¹æ“šæ™‚é–“ç”¢ç”Ÿä¸€å€‹æ–°çš„ (å¦‚æœæ˜¯æ–°æ›¸)
    if pd.isna(sys_id) or sys_id == '':
         sys_id = int(pd.Timestamp.now().timestamp() * 1000) + index # é¿å…é‡è¤‡
    
    sys_id_str = str(sys_id)
    
    # ã€å®‰å…¨æ¨¡å¼ã€‘è·³éå·²å­˜åœ¨
    if mode == '1' and sys_id_str in existing_ids:
        continue

    # æº–å‚™è³‡æ–™
    book_data = {
        'id': sys_id,
        'title': str(row.get('æ›¸å') or row.get('title') or ''),
        'author': str(row.get('ä½œè€…') or row.get('author') or 'æœªåˆ†é¡ä½œè€…'),
        'category': str(row.get('åˆ†é¡') or row.get('category') or 'æ–°æ›¸-å¾…å€Ÿ'),
        'note': str(row.get('å€Ÿé–±äºº_å‚™è¨»') or row.get('note') or ''),
        'date': str(row.get('æ—¥æœŸ') or row.get('date') or '')
    }
    
    # è™•ç†æ—¥æœŸæ ¼å¼ (å¦‚æœæ˜¯ Timestamp)
    if 'Timestamp' in str(type(row.get('æ—¥æœŸ', ''))):
         book_data['date'] = row['æ—¥æœŸ'].strftime('%Y-%m-%d')
    if pd.isna(book_data['date']) or book_data['date'] == 'NaT':
        book_data['date'] = ''
        
    if pd.isna(book_data['note']) or book_data['note'] == 'nan':
        book_data['note'] = ''

    # åˆ¤æ–· Document ID
    # ç‚ºäº†è®“ç¶²é èƒ½é †åˆ©æ“ä½œï¼Œæˆ‘å€‘å¯ä»¥ç”¨ Query æ‰¾ Docï¼Œæˆ–æ˜¯å¦‚æœé€™æ˜¯é·ç§»ä¾†çš„ï¼Œæˆ‘å€‘å¯èƒ½ä¸çŸ¥é“ Doc IDã€‚
    # ç­–ç•¥ï¼š
    # å¦‚æœæ˜¯è¦†è“‹æ¨¡å¼ï¼Œæˆ‘å€‘éœ€è¦å…ˆæ‰¾åˆ°è©² ID å°æ‡‰çš„ Doc ID (å¦‚æœæœ‰çš„è©±)ã€‚
    # é€™æœƒæ¯”è¼ƒæ…¢ã€‚
    # ç°¡åŒ–ç­–ç•¥ï¼šæˆ‘å€‘ç”¨ 'id' æ¬„ä½ç•¶ä½œè­˜åˆ¥ã€‚
    # ä½† Firestore çš„ Document ID æ˜¯éš¨æ©Ÿçš„ (æˆ–æ˜¯æˆ‘å€‘ä¹‹å‰è¨­çš„)ã€‚
    
    # ç‚ºäº†æ•ˆèƒ½ï¼Œå¦‚æœæ˜¯å¤§é‡åŒ¯å…¥ï¼Œæˆ‘å€‘ç›´æ¥ Add æ–°æ–‡ä»¶? ä¸è¡Œï¼Œæœƒé‡è¤‡ã€‚
    # æˆ‘å€‘ç”¨ Query æ‰¾æœ‰ç„¡æ­¤ ID
    
    # ç”±æ–¼ Batch Limit 500ï¼Œæˆ‘å€‘æ¯ 400 ç­†é€ä¸€æ¬¡ã€‚
    # é€™è£¡å¦‚æœä¸å…ˆ Queryï¼Œå¾ˆé›£åšã€Œæ›´æ–°ã€ã€‚
    # ç‚ºäº†ç°¡å–®èˆ‡æ•ˆèƒ½ï¼Œå‡è¨­æ˜¯ã€é‚„åŸã€‘ï¼šæˆ‘å€‘å…ˆæ¸…ç©ºï¼Ÿå¤ªå±éšªã€‚
    
    # å¯¦ä½œï¼šQuery by 'id'
    # é€™åœ¨ Loop è£¡åšæœƒå¾ˆæ…¢ã€‚
    
    # æ”¹é€²ï¼š
    # é€™è£¡çš„ restore ä¸»è¦æ˜¯çµ¦ã€Œå‚™ä»½é‚„åŸã€ç”¨ã€‚
    # ç•¶åˆ migrate æ˜¯ç”¨ batch addã€‚
    
    # æˆ‘å€‘æ¡ç”¨ã€Œé€é id æŸ¥è©¢ä¸¦å¯«å…¥ã€çš„æ–¹å¼ (é›–ç„¶æ…¢ä¸€é»ä½†æº–ç¢º)
    # æˆ–æ˜¯å¦‚æœä½¿ç”¨è€…ç¢ºå®šæ˜¯æƒ³ã€Œæ–°å¢ã€ï¼Œå°±ç›´æ¥ Addã€‚
    
    # é€™è£¡å¯¦ä½œã€ŒSmart Updateã€å¤ªè¤‡é›œï¼Œæˆ‘å€‘åšä¸€å€‹ç°¡å–®ç‰ˆï¼š
    # é‡å°æ¯ä¸€åˆ—ï¼Œç™¼é€ä¸€å€‹ set (merge=True) åˆ°ä¸€å€‹ä»¥ ID å‘½åçš„ Document?
    # ä¹‹å‰æˆ‘å€‘ migrate æ˜¯è®“ Firestore è‡ªå‹•ç”¢ç”Ÿ IDã€‚é€™æ¨£å°±ç„¡æ³•ç”¨ ID è¦†å¯«äº†ï¼
    # é€™æ˜¯å€‹å•é¡Œã€‚
    
    # è§£æ±ºæ–¹æ¡ˆï¼š
    # æˆ‘å€‘ç•¶åˆ migrate çš„æ™‚å€™ï¼ŒDoc ID æ˜¯è‡ªå‹•ç”¢ç”Ÿçš„ã€‚
    # æ‰€ä»¥è¦è¦†è“‹ï¼Œå¿…é ˆå…ˆçŸ¥é“ Doc IDã€‚
    # å‚™ä»½æª”è£¡é¢æ²’æœ‰ Doc ID (é™¤éæˆ‘å‰›æ”¹çš„ export æœ‰åŠ ï¼Ÿ)
    # æˆ‘å‰›å‰›æ”¹çš„ handleExport è£¡é¢æ²’æœ‰åŠ  docId (`books.map(book => ({ 'ç³»çµ±ID': book.id ... }))`)ã€‚
    # æ‰€ä»¥æˆ‘å€‘åªçŸ¥é“ internal IDã€‚
    
    # é€™æ¨£çš„è©±ï¼Œè¦ã€Œæ›´æ–°ã€èˆŠè³‡æ–™å¾ˆé›£ (å› ç‚ºä¸çŸ¥é“ Doc ID)ã€‚
    # é™¤éæˆ‘å€‘å…ˆä¸‹è¼‰æ‰€æœ‰ç¾æœ‰æ›¸çš„ ID -> DocID Mappingã€‚
    
    pass 

# é‡æ–°è¦åŠƒï¼š
# 1. ä¸‹è¼‰ç¾æœ‰ books (id -> doc_id map)
print("ğŸ” æ­£åœ¨ä¸‹è¼‰ ID å°ç…§è¡¨...")
id_map = {} # id (str) -> doc_id
docs = books_ref.stream()
for d in docs:
    dd = d.to_dict()
    if 'id' in dd:
        id_map[str(dd['id'])]] = d.id

# 2. è™•ç† Excel
for index, row in df.iterrows():
    sys_id = row.get('ç³»çµ±ID') or row.get('id')
    if pd.isna(sys_id) or sys_id == '':
         sys_id = int(pd.Timestamp.now().timestamp() * 1000) + index
    
    sys_id_str = str(sys_id)
    
    # æº–å‚™å…§å®¹
    book_data = {
        'id': sys_id,
        'title': str(row.get('æ›¸å') or row.get('title') or ''),
        'author': str(row.get('ä½œè€…') or row.get('author') or 'æœªåˆ†é¡ä½œè€…'),
        'category': str(row.get('åˆ†é¡') or row.get('category') or 'æ–°æ›¸-å¾…å€Ÿ'),
        'note': str(row.get('å€Ÿé–±äºº_å‚™è¨»') or row.get('note') or ''),
        'date': str(row.get('æ—¥æœŸ') or row.get('date') or '')
    }
    # Date clean
    if 'Timestamp' in str(type(row.get('æ—¥æœŸ', ''))):
         book_data['date'] = row['æ—¥æœŸ'].strftime('%Y-%m-%d')
    if pd.isna(book_data['date']) or book_data['date'] == 'NaT': book_data['date'] = ''
    if pd.isna(book_data['note']) or book_data['note'] == 'nan': book_data['note'] = ''

    # æ±ºå®š Ref
    doc_ref = None
    if sys_id_str in id_map:
        if mode == '1': continue # Skip existing
        doc_ref = books_ref.document(id_map[sys_id_str]) # Update existing
    else:
        doc_ref = books_ref.document() # Create new ID
        
    batch.set(doc_ref, book_data, merge=True)
    batch_count += 1
    total_processed += 1
    
    if batch_count >= 400:
        batch.commit()
        print(f"âœ… å·²è™•ç† {total_processed} ç­†...")
        batch = db.batch()
        batch_count = 0

if batch_count > 0:
    batch.commit()

print(f"\nğŸ‰ åŒ¯å…¥å®Œæˆï¼å…±è™•ç† {total_processed} ç­†è³‡æ–™ã€‚")
input("æŒ‰ Enter çµæŸ...")
